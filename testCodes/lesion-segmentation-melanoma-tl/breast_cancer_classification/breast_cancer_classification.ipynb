{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breast_cancer_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dYZMKC3AMYBN",
        "colab_type": "code",
        "outputId": "9dfa1850-1472-400a-f359-82ee80416f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Km8qwgpMiZX",
        "colab_type": "code",
        "outputId": "cfd4776a-ee8c-4873-ec66-2146d1c2d634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "% cd /content/drive/My Drive/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DQP0WSiYN3zp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# path details\n",
        "benign_path = []\n",
        "malignant_path = []\n",
        "\n",
        "# replace with your path\n",
        "benign_folder = '/content/drive/My Drive/data/benign/*.png'\n",
        "malignant_folder = '/content/drive/My Drive/data/malignant/*.png'\n",
        "\n",
        "for bimg in glob.glob(benign_folder):\n",
        "  benign_path.append(bimg)\n",
        "for mimg in glob.glob(malignant_folder):\n",
        "  malignant_path.append(mimg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uTrp9ElG86YK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5fa372ed-cd6c-4729-e4d2-851414217d53"
      },
      "cell_type": "code",
      "source": [
        "print(len(benign_path))\n",
        "print(len(malignant_path))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0_CRKmqK9UF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "NUM_CLASS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJKRxD-F9ANi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "cls0 = []\n",
        "cls1 = []\n",
        "\n",
        "for im in benign_path:\n",
        "  a = cv2.imread(im)\n",
        "  a = cv2.resize(a, (IMG_SIZE,IMG_SIZE))\n",
        "\n",
        "  cls0.append(a)\n",
        "  \n",
        "for im in malignant_path:\n",
        "  a = cv2.imread(im)\n",
        "  a = cv2.resize(a, (IMG_SIZE,IMG_SIZE))\n",
        "\n",
        "  cls1.append(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Onq-HjVt-R3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2e5161c3-8454-4e5a-f580-5494bcc42908"
      },
      "cell_type": "code",
      "source": [
        "print(len(cls0))\n",
        "print(len(cls1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MGdCo85g_vmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6b913d22-3c47-4302-c15d-d0d0e1882d57"
      },
      "cell_type": "code",
      "source": [
        "x = cls0[:]\n",
        "x.extend(cls1)\n",
        "print(len(x))\n",
        "\n",
        "y = []\n",
        "for i in range(len(cls0)):\n",
        "  y.append([1, 0])\n",
        "for i in range(len(cls1)):\n",
        "  y.append([0,1])\n",
        "  \n",
        "print(len(y))\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n",
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cGIowuHCAUgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "z = list(zip(x,y))\n",
        "\n",
        "random.shuffle(z)\n",
        "\n",
        "x = [a[0] for a in z]\n",
        "y = [a[1] for a in z]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qbAexAtvA_PT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c041511d-4eca-47eb-8e99-3cbe325beb5a"
      },
      "cell_type": "code",
      "source": [
        "tr_split = 0.85\n",
        "\n",
        "idx = int(len(x)*tr_split)\n",
        "\n",
        "x_train = x[:idx]\n",
        "y_train = y[:idx]\n",
        "x_test = x[idx:]\n",
        "y_test = y[idx:]\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(y_train))\n",
        "print(len(x_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68\n",
            "68\n",
            "12\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VG7tayXzBGwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8e319e1c-4545-4e19-86ff-e01c7d80caf3"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train = np.array(x_train, dtype = 'float32')\n",
        "x_test = np.array(x_test, dtype = 'float32')\n",
        "\n",
        "y_train = np.array(y_train, dtype = 'float32')\n",
        "y_test = np.array(y_test, dtype = 'float32')\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(68, 224, 224, 3)\n",
            "(12, 224, 224, 3)\n",
            "(68, 2)\n",
            "(12, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zj-iUX5cBMbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "32ad17bb-ccc7-4598-edf6-339900951f87"
      },
      "cell_type": "code",
      "source": [
        "x_train /= 255.\n",
        "\n",
        "print(np.min(x_train))\n",
        "print(np.mean(x_train))\n",
        "print(np.max(x_train))\n",
        "\n",
        "x_test /= 255.\n",
        "\n",
        "print(np.min(x_test))\n",
        "print(np.mean(x_test))\n",
        "print(np.max(x_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.7300422\n",
            "1.0\n",
            "0.08235294\n",
            "0.74446875\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7R3ZPZjdETyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VGG16 implementation\n",
        "# reference: https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.optimizers import SGD\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def VGG_16(weights_path=None):\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(NUM_CLASS, activation='softmax'))\n",
        "\n",
        "    if weights_path:\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "llS6VGkqE9G_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1491
        },
        "outputId": "4a8122a9-7655-4bc8-9c39-9e4f82b4b0f7"
      },
      "cell_type": "code",
      "source": [
        "VGG16 = VGG_16() # if transfer learning will be used, then keras default trained model should be used\n",
        "VGG16.summary()\n",
        "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "VGG16.compile(optimizer=sgd, loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d_108 (ZeroPadd (None, 226, 226, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_105 (Conv2D)          (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_109 (ZeroPadd (None, 226, 226, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_110 (ZeroPadd (None, 114, 114, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_111 (ZeroPadd (None, 114, 114, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_112 (ZeroPadd (None, 58, 58, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_113 (ZeroPadd (None, 58, 58, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_114 (ZeroPadd (None, 58, 58, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_115 (ZeroPadd (None, 30, 30, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_116 (ZeroPadd (None, 30, 30, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_117 (ZeroPadd (None, 30, 30, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_118 (ZeroPadd (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_119 (ZeroPadd (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_120 (ZeroPadd (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_117 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 134,268,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vmWJZ_kvGqPJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 5\n",
        "validation_split = 0.15\n",
        "verbose = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEgaSE-eFVBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "339636d1-42e1-4a16-a075-1ea084397ca6"
      },
      "cell_type": "code",
      "source": [
        "vgg16_hist = VGG16.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_split = validation_split, verbose = verbose)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 57 samples, validate on 11 samples\n",
            "Epoch 1/5\n",
            "57/57 [==============================] - 5s 95ms/step - loss: 0.7072 - acc: 0.4912 - val_loss: 0.6975 - val_acc: 0.4545\n",
            "Epoch 2/5\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.6951 - acc: 0.4737 - val_loss: 0.6923 - val_acc: 0.5455\n",
            "Epoch 3/5\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.7656 - acc: 0.4912 - val_loss: 0.6933 - val_acc: 0.4545\n",
            "Epoch 4/5\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.7125 - acc: 0.2982 - val_loss: 0.6903 - val_acc: 0.5455\n",
            "Epoch 5/5\n",
            "57/57 [==============================] - 2s 39ms/step - loss: 0.7053 - acc: 0.4386 - val_loss: 0.6908 - val_acc: 0.5455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NsfxiA1AG_8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "243578db-507c-4038-e76b-d6047770eb45"
      },
      "cell_type": "code",
      "source": [
        "VGG16.evaluate(x_test, y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r12/12 [==============================] - 2s 132ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6936222910881042, 0.5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "oEOJW3VxK2uw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ResNet-50 implementation in Keras\n",
        "# reference: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "import keras.backend as K\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.engine.topology import get_source_inputs\n",
        "\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the filterss of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size,\n",
        "               padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the filterss of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
        "    And the shortcut should have strides=(2,2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
        "               name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same',\n",
        "               name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
        "                      name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(include_top=True, weights=None,\n",
        "             input_tensor=None, input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=NUM_CLASS):\n",
        "    \"\"\"Instantiates the ResNet50 architecture.\n",
        "    Optionally loads weights pre-trained\n",
        "    on ImageNet. Note that when using TensorFlow,\n",
        "    for best performance you should set\n",
        "    `image_data_format=\"channels_last\"` in your Keras config\n",
        "    at ~/.keras/keras.json.\n",
        "    The model and the weights are compatible with both\n",
        "    TensorFlow and Theano. The data format\n",
        "    convention used by the model is the one\n",
        "    specified in your Keras config file.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization)\n",
        "            or \"imagenet\" (pre-training on ImageNet).\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
        "            or `(3, 224, 244)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 197.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional layer.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "   \n",
        "    # Determine proper input shape\n",
        "    input_shape = (224,224,3)\n",
        "\n",
        "\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    img_input = Input(shape = (224,224,3))\n",
        "    x = ZeroPadding2D((3, 3))(img_input)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='resnet50')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vrPLFg6_NP28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6878
        },
        "outputId": "15794647-1c55-46a5-8da5-841a1ba655a5"
      },
      "cell_type": "code",
      "source": [
        "Resnet50 = ResNet50() # if transfer learning will be used, then keras default trained model should be used\n",
        "Resnet50.summary()\n",
        "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "Resnet50.compile(optimizer=sgd, loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_122 (ZeroPadding (None, 230, 230, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        zero_padding2d_122[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling2D) (None, 55, 55, 64)   0           activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_48[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_48[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 55, 55, 256)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 55, 55, 256)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 55, 55, 256)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 28, 28, 512)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 28, 28, 512)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 28, 28, 512)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 28, 28, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 14, 14, 1024) 0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 14, 14, 1024) 0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 14, 14, 1024) 0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 14, 14, 1024) 0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 14, 14, 1024) 0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 14, 14, 1024) 0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 2048)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 2048)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 2048)   0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1000 (Dense)                  (None, 2)            4098        flatten_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 23,591,810\n",
            "Trainable params: 23,538,690\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vCpB1u2qNlE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 5\n",
        "validation_split = 0.15\n",
        "verbose = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbPy1luLOq7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "f72cb6e3-725c-4f28-d560-9c04fd80ef8c"
      },
      "cell_type": "code",
      "source": [
        "resnet50_hist = Resnet50.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_split = validation_split, verbose = verbose)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 57 samples, validate on 11 samples\n",
            "Epoch 1/5\n",
            "57/57 [==============================] - 18s 321ms/step - loss: 6.4002 - acc: 0.4386 - val_loss: 8.7438 - val_acc: 0.4545\n",
            "Epoch 2/5\n",
            "57/57 [==============================] - 2s 34ms/step - loss: 7.8745 - acc: 0.5088 - val_loss: 8.7438 - val_acc: 0.4545\n",
            "Epoch 3/5\n",
            "57/57 [==============================] - 2s 33ms/step - loss: 7.8745 - acc: 0.5088 - val_loss: 8.7438 - val_acc: 0.4545\n",
            "Epoch 4/5\n",
            "57/57 [==============================] - 2s 34ms/step - loss: 7.8745 - acc: 0.5088 - val_loss: 8.7438 - val_acc: 0.4545\n",
            "Epoch 5/5\n",
            "57/57 [==============================] - 2s 33ms/step - loss: 7.8745 - acc: 0.5088 - val_loss: 8.7438 - val_acc: 0.4545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Jno8RJ0OyD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "987eca3e-9bb0-4af6-c9eb-a6ae8b7dabe8"
      },
      "cell_type": "code",
      "source": [
        "Resnet50.evaluate(x_test, y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r12/12 [==============================] - 1s 68ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.015119552612305, 0.5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "KJm86_4ZPJks",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# InceptionV3 implementation in Keras\n",
        "# reference: https://github.com/fchollet/deep-learning-models/blob/master/inception_v3.py\n",
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "\n",
        "def conv2d_bn(x,\n",
        "              filters,\n",
        "              num_row,\n",
        "              num_col,\n",
        "              padding='same',\n",
        "              strides=(1, 1),\n",
        "              name=None):\n",
        "    \"\"\"Utility function to apply conv + BN.\n",
        "    Arguments:\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        num_row: height of the convolution kernel.\n",
        "        num_col: width of the convolution kernel.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_conv'`\n",
        "            for the convolution and `name + '_bn'` for the\n",
        "            batch norm layer.\n",
        "    Returns:\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    if name is not None:\n",
        "        bn_name = name + '_bn'\n",
        "        conv_name = name + '_conv'\n",
        "    else:\n",
        "        bn_name = None\n",
        "        conv_name = None\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        bn_axis = 1\n",
        "    else:\n",
        "        bn_axis = 3\n",
        "    x = Conv2D(\n",
        "        filters, (num_row, num_col),\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        use_bias=False,\n",
        "        name=conv_name)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
        "    x = Activation('relu', name=name)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionV3(include_top=True,\n",
        "                weights=None,\n",
        "                input_tensor=None,\n",
        "                input_shape=None,\n",
        "                pooling=None,\n",
        "                classes=NUM_CLASS):\n",
        "    \"\"\"Instantiates the Inception v3 architecture.\n",
        "    Optionally loads weights pre-trained\n",
        "    on ImageNet. Note that when using TensorFlow,\n",
        "    for best performance you should set\n",
        "    `image_data_format=\"channels_last\"` in your Keras config\n",
        "    at ~/.keras/keras.json.\n",
        "    The model and the weights are compatible with both\n",
        "    TensorFlow and Theano. The data format\n",
        "    convention used by the model is the one\n",
        "    specified in your Keras config file.\n",
        "    Note that the default input image size for this model is 299x299.\n",
        "    Arguments:\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization)\n",
        "            or \"imagenet\" (pre-training on ImageNet).\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(299, 299, 3)` (with `channels_last` data format)\n",
        "            or `(3, 299, 299)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 139.\n",
        "            E.g. `(150, 150, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional layer.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    Returns:\n",
        "        A Keras model instance.\n",
        "    Raises:\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = (224,224,3)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "\n",
        "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
        "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
        "    x = conv2d_bn(x, 64, 3, 3)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv2d_bn(x, 80, 1, 1, padding='valid')\n",
        "    x = conv2d_bn(x, 192, 3, 3, padding='valid')\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    # mixed 0, 1, 2: 35 x 35 x 256\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed0')\n",
        "\n",
        "    # mixed 1: 35 x 35 x 256\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed1')\n",
        "\n",
        "    # mixed 2: 35 x 35 x 256\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed2')\n",
        "\n",
        "    # mixed 3: 17 x 17 x 768\n",
        "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(\n",
        "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = layers.concatenate(\n",
        "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
        "\n",
        "    # mixed 4: 17 x 17 x 768\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed4')\n",
        "\n",
        "    # mixed 5, 6: 17 x 17 x 768\n",
        "    for i in range(2):\n",
        "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "        branch_pool = AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name='mixed' + str(5 + i))\n",
        "\n",
        "    # mixed 7: 17 x 17 x 768\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed7')\n",
        "\n",
        "    # mixed 8: 8 x 8 x 1280\n",
        "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
        "                          strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
        "    branch7x7x3 = conv2d_bn(\n",
        "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = layers.concatenate(\n",
        "        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name='mixed8')\n",
        "\n",
        "    # mixed 9: 8 x 8 x 2048\n",
        "    for i in range(2):\n",
        "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
        "\n",
        "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
        "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
        "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
        "        branch3x3 = layers.concatenate(\n",
        "            [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
        "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
        "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
        "        branch3x3dbl = layers.concatenate(\n",
        "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
        "\n",
        "        branch_pool = AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name='mixed' + str(9 + i))\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='inception_v3')\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v3tsCoQ1P_jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12175
        },
        "outputId": "5b474d8b-22d2-424d-c10b-97b412288d45"
      },
      "cell_type": "code",
      "source": [
        "Inceptionv3 = InceptionV3()\n",
        "Inceptionv3.summary()\n",
        "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "Inceptionv3.compile(optimizer=sgd, loss='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 111, 111, 32) 864         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 111, 111, 32) 96          conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 111, 111, 32) 0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 109, 109, 32) 9216        activation_430[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 109, 109, 32) 96          conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 109, 109, 32) 0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 109, 109, 64) 18432       activation_431[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 109, 109, 64) 192         conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 109, 109, 64) 0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_61 (MaxPooling2D) (None, 54, 54, 64)   0           activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_61[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 54, 54, 80)   240         conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 54, 54, 80)   0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 52, 52, 192)  138240      activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 52, 52, 192)  576         conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 52, 52, 192)  0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling2D) (None, 25, 25, 192)  0           activation_434[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_62[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 25, 25, 64)   192         conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 25, 25, 64)   0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_62[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 25, 25, 96)   55296       activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 25, 25, 48)   144         conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 25, 25, 96)   288         conv2d_409[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 25, 25, 48)   0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 25, 25, 96)   0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_62[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_62[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 25, 25, 64)   76800       activation_436[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 25, 25, 96)   82944       activation_439[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 25, 25, 64)   192         conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 25, 25, 64)   192         conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 25, 25, 96)   288         conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 25, 25, 32)   96          conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 25, 25, 64)   0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 25, 25, 64)   0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 25, 25, 96)   0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 25, 25, 32)   0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_435[0][0]             \n",
            "                                                                 activation_437[0][0]             \n",
            "                                                                 activation_440[0][0]             \n",
            "                                                                 activation_441[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 25, 25, 64)   192         conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_445 (Activation)     (None, 25, 25, 64)   0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 25, 25, 96)   55296       activation_445[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 25, 25, 48)   144         conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 25, 25, 96)   288         conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_443 (Activation)     (None, 25, 25, 48)   0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_446 (Activation)     (None, 25, 25, 96)   0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_29 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 25, 25, 64)   76800       activation_443[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 25, 25, 96)   82944       activation_446[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 25, 25, 64)   192         conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 25, 25, 64)   192         conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 25, 25, 96)   288         conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 25, 25, 64)   192         conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_442 (Activation)     (None, 25, 25, 64)   0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_444 (Activation)     (None, 25, 25, 64)   0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_447 (Activation)     (None, 25, 25, 96)   0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_448 (Activation)     (None, 25, 25, 64)   0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_442[0][0]             \n",
            "                                                                 activation_444[0][0]             \n",
            "                                                                 activation_447[0][0]             \n",
            "                                                                 activation_448[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 25, 25, 64)   192         conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_452 (Activation)     (None, 25, 25, 64)   0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 25, 25, 96)   55296       activation_452[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 25, 25, 48)   144         conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 25, 25, 96)   288         conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_450 (Activation)     (None, 25, 25, 48)   0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_453 (Activation)     (None, 25, 25, 96)   0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_30 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 25, 25, 64)   76800       activation_450[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 25, 25, 96)   82944       activation_453[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 25, 25, 64)   192         conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 25, 25, 64)   192         conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 25, 25, 96)   288         conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 25, 25, 64)   192         conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_449 (Activation)     (None, 25, 25, 64)   0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_451 (Activation)     (None, 25, 25, 64)   0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_454 (Activation)     (None, 25, 25, 96)   0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_455 (Activation)     (None, 25, 25, 64)   0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_449[0][0]             \n",
            "                                                                 activation_451[0][0]             \n",
            "                                                                 activation_454[0][0]             \n",
            "                                                                 activation_455[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 25, 25, 64)   192         conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_457 (Activation)     (None, 25, 25, 64)   0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 25, 25, 96)   55296       activation_457[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 25, 25, 96)   288         conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_458 (Activation)     (None, 25, 25, 96)   0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 12, 12, 96)   82944       activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 12, 12, 384)  1152        conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 12, 12, 96)   288         conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_456 (Activation)     (None, 12, 12, 384)  0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_459 (Activation)     (None, 12, 12, 96)   0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_63 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_456[0][0]             \n",
            "                                                                 activation_459[0][0]             \n",
            "                                                                 max_pooling2d_63[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 12, 12, 128)  384         conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_464 (Activation)     (None, 12, 12, 128)  0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 12, 12, 128)  114688      activation_464[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 12, 12, 128)  384         conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_465 (Activation)     (None, 12, 12, 128)  0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 12, 12, 128)  114688      activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 12, 12, 128)  384         conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 12, 12, 128)  384         conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_461 (Activation)     (None, 12, 12, 128)  0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_466 (Activation)     (None, 12, 12, 128)  0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 12, 12, 128)  114688      activation_461[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 12, 12, 128)  114688      activation_466[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 12, 12, 128)  384         conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 12, 12, 128)  384         conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_462 (Activation)     (None, 12, 12, 128)  0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_467 (Activation)     (None, 12, 12, 128)  0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_31 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 12, 12, 192)  172032      activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 12, 12, 192)  172032      activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 12, 12, 192)  576         conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 12, 12, 192)  576         conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 12, 12, 192)  576         conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 12, 12, 192)  576         conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_460 (Activation)     (None, 12, 12, 192)  0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_463 (Activation)     (None, 12, 12, 192)  0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_468 (Activation)     (None, 12, 12, 192)  0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_469 (Activation)     (None, 12, 12, 192)  0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_460[0][0]             \n",
            "                                                                 activation_463[0][0]             \n",
            "                                                                 activation_468[0][0]             \n",
            "                                                                 activation_469[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_444 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 12, 12, 160)  480         conv2d_444[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, 12, 12, 160)  0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_445 (Conv2D)             (None, 12, 12, 160)  179200      activation_474[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 12, 12, 160)  480         conv2d_445[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_475 (Activation)     (None, 12, 12, 160)  0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_446 (Conv2D)             (None, 12, 12, 160)  179200      activation_475[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 12, 12, 160)  480         conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 12, 12, 160)  480         conv2d_446[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, 12, 12, 160)  0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, 12, 12, 160)  0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 12, 12, 160)  179200      activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_447 (Conv2D)             (None, 12, 12, 160)  179200      activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 12, 12, 160)  480         conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 12, 12, 160)  480         conv2d_447[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, 12, 12, 160)  0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, 12, 12, 160)  0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_443 (Conv2D)             (None, 12, 12, 192)  215040      activation_472[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 12, 12, 192)  215040      activation_477[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_449 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 12, 12, 192)  576         conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 12, 12, 192)  576         conv2d_443[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 12, 12, 192)  576         conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 12, 12, 192)  576         conv2d_449[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_470 (Activation)     (None, 12, 12, 192)  0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, 12, 12, 192)  0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, 12, 12, 192)  0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, 12, 12, 192)  0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_470[0][0]             \n",
            "                                                                 activation_473[0][0]             \n",
            "                                                                 activation_478[0][0]             \n",
            "                                                                 activation_479[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 12, 12, 160)  480         conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, 12, 12, 160)  0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 12, 12, 160)  179200      activation_484[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 12, 12, 160)  480         conv2d_455[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, 12, 12, 160)  0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 12, 12, 160)  179200      activation_485[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 12, 12, 160)  480         conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 12, 12, 160)  480         conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, 12, 12, 160)  0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, 12, 12, 160)  0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 12, 12, 160)  179200      activation_481[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 12, 12, 160)  179200      activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 12, 12, 160)  480         conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 12, 12, 160)  480         conv2d_457[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, 12, 12, 160)  0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, 12, 12, 160)  0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_33 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 12, 12, 192)  215040      activation_482[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 12, 12, 192)  215040      activation_487[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 12, 12, 192)  576         conv2d_450[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 12, 12, 192)  576         conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 12, 12, 192)  576         conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 12, 12, 192)  576         conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, 12, 12, 192)  0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, 12, 12, 192)  0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, 12, 12, 192)  0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, 12, 12, 192)  0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_480[0][0]             \n",
            "                                                                 activation_483[0][0]             \n",
            "                                                                 activation_488[0][0]             \n",
            "                                                                 activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_464 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 12, 12, 192)  576         conv2d_464[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, 12, 12, 192)  0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_465 (Conv2D)             (None, 12, 12, 192)  258048      activation_494[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 12, 12, 192)  576         conv2d_465[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, 12, 12, 192)  0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_461 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_466 (Conv2D)             (None, 12, 12, 192)  258048      activation_495[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 12, 12, 192)  576         conv2d_461[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 12, 12, 192)  576         conv2d_466[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, 12, 12, 192)  0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, 12, 12, 192)  0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_462 (Conv2D)             (None, 12, 12, 192)  258048      activation_491[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_467 (Conv2D)             (None, 12, 12, 192)  258048      activation_496[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 12, 12, 192)  576         conv2d_462[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 12, 12, 192)  576         conv2d_467[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, 12, 12, 192)  0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, 12, 12, 192)  0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_34 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_463 (Conv2D)             (None, 12, 12, 192)  258048      activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_468 (Conv2D)             (None, 12, 12, 192)  258048      activation_497[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_469 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 12, 12, 192)  576         conv2d_460[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 12, 12, 192)  576         conv2d_463[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 12, 12, 192)  576         conv2d_468[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 12, 12, 192)  576         conv2d_469[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, 12, 12, 192)  0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, 12, 12, 192)  0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, 12, 12, 192)  0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, 12, 12, 192)  0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_490[0][0]             \n",
            "                                                                 activation_493[0][0]             \n",
            "                                                                 activation_498[0][0]             \n",
            "                                                                 activation_499[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_472 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 12, 12, 192)  576         conv2d_472[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, 12, 12, 192)  0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_473 (Conv2D)             (None, 12, 12, 192)  258048      activation_502[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 12, 12, 192)  576         conv2d_473[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_503 (Activation)     (None, 12, 12, 192)  0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_470 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_474 (Conv2D)             (None, 12, 12, 192)  258048      activation_503[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 12, 12, 192)  576         conv2d_470[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 12, 12, 192)  576         conv2d_474[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, 12, 12, 192)  0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_504 (Activation)     (None, 12, 12, 192)  0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_471 (Conv2D)             (None, 5, 5, 320)    552960      activation_500[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_475 (Conv2D)             (None, 5, 5, 192)    331776      activation_504[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 5, 5, 320)    960         conv2d_471[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 5, 5, 192)    576         conv2d_475[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, 5, 5, 320)    0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_505 (Activation)     (None, 5, 5, 192)    0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_501[0][0]             \n",
            "                                                                 activation_505[0][0]             \n",
            "                                                                 max_pooling2d_64[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_480 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 5, 5, 448)    1344        conv2d_480[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_510 (Activation)     (None, 5, 5, 448)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_477 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_481 (Conv2D)             (None, 5, 5, 384)    1548288     activation_510[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 5, 5, 384)    1152        conv2d_477[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 5, 5, 384)    1152        conv2d_481[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_507 (Activation)     (None, 5, 5, 384)    0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_511 (Activation)     (None, 5, 5, 384)    0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_478 (Conv2D)             (None, 5, 5, 384)    442368      activation_507[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_479 (Conv2D)             (None, 5, 5, 384)    442368      activation_507[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_482 (Conv2D)             (None, 5, 5, 384)    442368      activation_511[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_483 (Conv2D)             (None, 5, 5, 384)    442368      activation_511[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_35 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_476 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 5, 5, 384)    1152        conv2d_478[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 5, 5, 384)    1152        conv2d_479[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 5, 5, 384)    1152        conv2d_482[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 5, 5, 384)    1152        conv2d_483[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_484 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 5, 5, 320)    960         conv2d_476[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_508 (Activation)     (None, 5, 5, 384)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_509 (Activation)     (None, 5, 5, 384)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_512 (Activation)     (None, 5, 5, 384)    0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_513 (Activation)     (None, 5, 5, 384)    0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 5, 5, 192)    576         conv2d_484[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_506 (Activation)     (None, 5, 5, 320)    0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_508[0][0]             \n",
            "                                                                 activation_509[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 5, 5, 768)    0           activation_512[0][0]             \n",
            "                                                                 activation_513[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_514 (Activation)     (None, 5, 5, 192)    0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_506[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_7[0][0]              \n",
            "                                                                 activation_514[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 5, 5, 448)    1344        conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_519 (Activation)     (None, 5, 5, 448)    0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_486 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, 5, 5, 384)    1548288     activation_519[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 5, 5, 384)    1152        conv2d_486[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 5, 5, 384)    1152        conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_516 (Activation)     (None, 5, 5, 384)    0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_520 (Activation)     (None, 5, 5, 384)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_487 (Conv2D)             (None, 5, 5, 384)    442368      activation_516[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_488 (Conv2D)             (None, 5, 5, 384)    442368      activation_516[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, 5, 5, 384)    442368      activation_520[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, 5, 5, 384)    442368      activation_520[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_36 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_485 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 5, 5, 384)    1152        conv2d_487[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 5, 5, 384)    1152        conv2d_488[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 5, 5, 384)    1152        conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 5, 5, 384)    1152        conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 5, 5, 320)    960         conv2d_485[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_517 (Activation)     (None, 5, 5, 384)    0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_518 (Activation)     (None, 5, 5, 384)    0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_521 (Activation)     (None, 5, 5, 384)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_522 (Activation)     (None, 5, 5, 384)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 5, 5, 192)    576         conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_515 (Activation)     (None, 5, 5, 320)    0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_517[0][0]             \n",
            "                                                                 activation_518[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 5, 5, 768)    0           activation_521[0][0]             \n",
            "                                                                 activation_522[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_523 (Activation)     (None, 5, 5, 192)    0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_515[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_8[0][0]              \n",
            "                                                                 activation_523[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 2)            4098        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 21,806,882\n",
            "Trainable params: 21,772,450\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mVuAs5S_QFcm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 5\n",
        "validation_split = 0.15\n",
        "verbose = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZxuWaYX1Qbp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "b61ab6df-dbe5-418c-9ce5-d0b97fdcf8a4"
      },
      "cell_type": "code",
      "source": [
        "inceptionv3_hist = Inceptionv3.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_split = validation_split, verbose = verbose)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 57 samples, validate on 11 samples\n",
            "Epoch 1/5\n",
            "57/57 [==============================] - 35s 611ms/step - loss: 3.4842 - acc: 0.4561 - val_loss: 8.7438 - val_acc: 0.4545\n",
            "Epoch 2/5\n",
            "57/57 [==============================] - 2s 29ms/step - loss: 1.1231 - acc: 0.4912 - val_loss: 8.7438 - val_acc: 0.4545\n",
            "Epoch 3/5\n",
            "57/57 [==============================] - 2s 28ms/step - loss: 0.6248 - acc: 0.6842 - val_loss: 8.7438 - val_acc: 0.4545\n",
            "Epoch 4/5\n",
            "57/57 [==============================] - 2s 28ms/step - loss: 0.4210 - acc: 0.8246 - val_loss: 8.7438 - val_acc: 0.4545\n",
            "Epoch 5/5\n",
            "57/57 [==============================] - 2s 29ms/step - loss: 0.5195 - acc: 0.8070 - val_loss: 8.7438 - val_acc: 0.4545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zM9dgwoNQmC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5b6041b1-f9a1-4e7d-f9cd-72d62e5715a1"
      },
      "cell_type": "code",
      "source": [
        "Inceptionv3.evaluate(x_test, y_test)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r12/12 [==============================] - 1s 59ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.015119552612305, 0.5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "fu6mRN-KRSVs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# To-do, new model, augmentation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SP1zUTucRW1V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}